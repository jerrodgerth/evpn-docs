{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction # As data center technologies continue to evolve, and the need to offer higher speeds is matched with a need for operational efficiencies and flexibility. Key to this are the evolving service demands operators are seeing with new requirements driven by new applications that can\u2019t be solved by existing technologies. Existing layer 2 service technologies such as standard LAN broadcast domains, MPLS/VPLS, and PBB are both proven solutions for delivering services, but the control plane approach hasn\u2019t changed and these technologies still rely on Layer 2 flooding and learning to build the forwarding database (FDB). L3 VPN services leverage BGP for building their FDBs which is more efficient, but doesn\u2019t provide tunneling flexibility. EVPN introduces a new model for L2 and L3 services delivery that inherits over a decade of operational experience with IP VPN and VPLS in production networks, and incorporates flexibility for service delivery over Layer 3 networks. In EVPN the control plane and data plane are abstracted and separated. The multiprotocol \u2013BGP (MP-BGP) control plane protocol carries MAC/IP routing information, and EVPN provides several choices for the data plane encapsulation. EVPN enables data center operators to meet emerging needs in their networks with a single VPN technology: Integrated Layer 2 and Layer 3 VPN services Data center interconnect (DCI) Cloud and virtualization services Network simplification with less protocols Operational consistency across services and vendors","title":"Intro"},{"location":"#introduction","text":"As data center technologies continue to evolve, and the need to offer higher speeds is matched with a need for operational efficiencies and flexibility. Key to this are the evolving service demands operators are seeing with new requirements driven by new applications that can\u2019t be solved by existing technologies. Existing layer 2 service technologies such as standard LAN broadcast domains, MPLS/VPLS, and PBB are both proven solutions for delivering services, but the control plane approach hasn\u2019t changed and these technologies still rely on Layer 2 flooding and learning to build the forwarding database (FDB). L3 VPN services leverage BGP for building their FDBs which is more efficient, but doesn\u2019t provide tunneling flexibility. EVPN introduces a new model for L2 and L3 services delivery that inherits over a decade of operational experience with IP VPN and VPLS in production networks, and incorporates flexibility for service delivery over Layer 3 networks. In EVPN the control plane and data plane are abstracted and separated. The multiprotocol \u2013BGP (MP-BGP) control plane protocol carries MAC/IP routing information, and EVPN provides several choices for the data plane encapsulation. EVPN enables data center operators to meet emerging needs in their networks with a single VPN technology: Integrated Layer 2 and Layer 3 VPN services Data center interconnect (DCI) Cloud and virtualization services Network simplification with less protocols Operational consistency across services and vendors","title":"Introduction"},{"location":"benefits/","text":"Key EVPN Benefits # There are several important EVPN benefits that enable service providers to simplify their networks and offer advanced Ethernet services. Integrated Services # Delivering Layer 2 and Layer 3 services over the same interface, VLAN and VPN using a single VPN technology has been cumbersome until now. While service providers can offer services with VPLS and L3VPNs, it requires multiple technologies and multiple customer service interfaces. L3VPN-like operation with MP-BGP as the control plane protocol offers more scalability and control over learning and flooding. Network Efficiency # Multihoming with all-active forwarding, and load balancing between provider edge routers (PEs) is key to providing redundant and efficient services within the data center, between them for DCI services or for hybrid cloud interconnect services. All-active forwarding means that all links are active and used in the network, and there is no wasted idle capacity for standby links. More efficient hybrid service can be delivered over a single interface or VLAN, instead of using multiple interfaces or VLANs for multiple services. Design Flexibility # Since the control plane and data plane are separated, several MPLS or IP data plane encapsulation choices are available to meet core network requirements. Provisioning and management using a single VPN technology is simpler, instead of managing a Layer 2 and Layer 3 VPN technology. Greater Control # MAC/IP provisioning from a network management system database enables programmatic network control, and control plane signaling maintains a consistent signaled FDB instead of flooding and learning in the data plane. Proxy ARP/ND functionality allows PEs to respond to ARP/ND requests locally, which reduces or eliminates flooding. EVPN also builds on consensus and cooperation between router vendors and service providers working together on a simple and interoperable technology. Since 2014, Nokia has worked in the IETF to lead the standardization of EVPN (greater than 20 Internet drafts) and committed to interop testing at EANTC with all major EVPN vendors. Nokia completeness of EVPN feature set is widely recognized in the industry, and has become the basis for delivery of enhanced VPN services by many operators worldwide.","title":"Benefits"},{"location":"benefits/#key-evpn-benefits","text":"There are several important EVPN benefits that enable service providers to simplify their networks and offer advanced Ethernet services.","title":"Key EVPN Benefits"},{"location":"benefits/#integrated-services","text":"Delivering Layer 2 and Layer 3 services over the same interface, VLAN and VPN using a single VPN technology has been cumbersome until now. While service providers can offer services with VPLS and L3VPNs, it requires multiple technologies and multiple customer service interfaces. L3VPN-like operation with MP-BGP as the control plane protocol offers more scalability and control over learning and flooding.","title":"Integrated Services"},{"location":"benefits/#network-efficiency","text":"Multihoming with all-active forwarding, and load balancing between provider edge routers (PEs) is key to providing redundant and efficient services within the data center, between them for DCI services or for hybrid cloud interconnect services. All-active forwarding means that all links are active and used in the network, and there is no wasted idle capacity for standby links. More efficient hybrid service can be delivered over a single interface or VLAN, instead of using multiple interfaces or VLANs for multiple services.","title":"Network Efficiency"},{"location":"benefits/#design-flexibility","text":"Since the control plane and data plane are separated, several MPLS or IP data plane encapsulation choices are available to meet core network requirements. Provisioning and management using a single VPN technology is simpler, instead of managing a Layer 2 and Layer 3 VPN technology.","title":"Design Flexibility"},{"location":"benefits/#greater-control","text":"MAC/IP provisioning from a network management system database enables programmatic network control, and control plane signaling maintains a consistent signaled FDB instead of flooding and learning in the data plane. Proxy ARP/ND functionality allows PEs to respond to ARP/ND requests locally, which reduces or eliminates flooding. EVPN also builds on consensus and cooperation between router vendors and service providers working together on a simple and interoperable technology. Since 2014, Nokia has worked in the IETF to lead the standardization of EVPN (greater than 20 Internet drafts) and committed to interop testing at EANTC with all major EVPN vendors. Nokia completeness of EVPN feature set is widely recognized in the industry, and has become the basis for delivery of enhanced VPN services by many operators worldwide.","title":"Greater Control"},{"location":"dataplanes/","text":"EVPN Data Planes # There are several I-Ds for data plane encapsulation, MPLS (RFC-7432), PBB (RFC-7623), and NVO (RFC 8365). A summary of the currently supported NVO VXLAN encapsulation SR-Linux supports is provided below. The data plane is separated from the control plane, so the EVPN functionality is the same over any data plane encapsulation. Network Virtualization Overlay (NVO) # NVO defines 3 encapsulation types; VXLAN, NVGRE, and MPLSoGRE. While each could be used for a variety of use cases, the industry has gravitated towards use of VXLAN primarily in the data center. For this reason, Nokia\u2019s SR Linux has implemented the VXLAN data plane (RFC 7348) for EVPN L2 and L3 services. FIGURE VXLAN addresses the data plane needs for overlay networks within virtualized data centers accommodating multiple tenants. The main attributes of the VXLAN encapsulation are: VXLAN is an overlay network encapsulation used to carry MAC traffic between VMs over a logical Layer 3 tunnel. Avoids the Layer 2 MAC explosion, because VM MACs are only learned at the edge of the network. Core nodes simply route the traffic based on the destination IP (which is the system IP address of the remote PE or VTEP-VXLAN Tunnel End Point). Supports multi-path scalability through ECMP (to a remote VTEP address, based on source UDP port entropy) while preserving the Layer 2 connectivity between VMs. xSTP is no longer needed in the network. Supports multiple tenants, each with their own isolated Layer 2 domain. The tenant identifier is encoded in the VNI field (VXLAN Network Identifier) and allows up to 16M values, as opposed to the 4k values provided by the 802.1q VLAN space. As shown in Figure XXX, VXLAN encapsulates the inner Ethernet frames into VXLAN + UDP/IP packets. The main pieces of information encoded in this encapsulation are: VXLAN header (8 bytes) Flags (8 bits) where the I flag is set to 1 to indicate that the VNI is present and valid. The rest of the flags (\u201cReserved\u201d bits) are set to 0 Includes the VNI field (24-bit value) or VXLAN network identifier. It identifies an isolated Layer 2 domain within the DC network. The rest of the fields are reserved for future use. FIGURE","title":"Data Planes"},{"location":"dataplanes/#evpn-data-planes","text":"There are several I-Ds for data plane encapsulation, MPLS (RFC-7432), PBB (RFC-7623), and NVO (RFC 8365). A summary of the currently supported NVO VXLAN encapsulation SR-Linux supports is provided below. The data plane is separated from the control plane, so the EVPN functionality is the same over any data plane encapsulation.","title":"EVPN Data Planes"},{"location":"dataplanes/#network-virtualization-overlay-nvo","text":"NVO defines 3 encapsulation types; VXLAN, NVGRE, and MPLSoGRE. While each could be used for a variety of use cases, the industry has gravitated towards use of VXLAN primarily in the data center. For this reason, Nokia\u2019s SR Linux has implemented the VXLAN data plane (RFC 7348) for EVPN L2 and L3 services. FIGURE VXLAN addresses the data plane needs for overlay networks within virtualized data centers accommodating multiple tenants. The main attributes of the VXLAN encapsulation are: VXLAN is an overlay network encapsulation used to carry MAC traffic between VMs over a logical Layer 3 tunnel. Avoids the Layer 2 MAC explosion, because VM MACs are only learned at the edge of the network. Core nodes simply route the traffic based on the destination IP (which is the system IP address of the remote PE or VTEP-VXLAN Tunnel End Point). Supports multi-path scalability through ECMP (to a remote VTEP address, based on source UDP port entropy) while preserving the Layer 2 connectivity between VMs. xSTP is no longer needed in the network. Supports multiple tenants, each with their own isolated Layer 2 domain. The tenant identifier is encoded in the VNI field (VXLAN Network Identifier) and allows up to 16M values, as opposed to the 4k values provided by the 802.1q VLAN space. As shown in Figure XXX, VXLAN encapsulates the inner Ethernet frames into VXLAN + UDP/IP packets. The main pieces of information encoded in this encapsulation are: VXLAN header (8 bytes) Flags (8 bits) where the I flag is set to 1 to indicate that the VNI is present and valid. The rest of the flags (\u201cReserved\u201d bits) are set to 0 Includes the VNI field (24-bit value) or VXLAN network identifier. It identifies an isolated Layer 2 domain within the DC network. The rest of the fields are reserved for future use. FIGURE","title":"Network Virtualization Overlay (NVO)"},{"location":"overview/","text":"EVPN Overview # Now that we\u2019ve discussed the motivation and key benefits of EVPN, let\u2019s dive into how the technology is developing. EVPN technology is driven in the IETF L2VPN WG, comprised of a few mature base internet drafts (I-Ds) as well as a plethora of new I-Ds that extend EVPN functionality (over 20 I-Ds in total). No more changes are expected on the base specification, and there are several shipping EVPN implementations. The authors of the EVPN requirements and base specification I-Ds come from a diverse set of router vendors (Nokia (Alcatel-Lucent at the time), Cisco, Juniper) and network operators (Arktan, AT&T, Bloomberg, Verizon). EVPN isn\u2019t just another bright idea that someone came up with in a dark cave by themselves, it\u2019s a collaboration between multiple router vendors and network operators that are working together to define this new technology. FIGURE EVPN introduces the concept of a separate control plane and data plane, which enables IP/MAC learning to be performed in the control plane instead of the data plane. MP-BGP is used as the control plane protocol, which brings proven and inherent BGP control plane scalability to MAC routes, and can even be extended with hierarchy and route reflection. Using control plane learning provides a consistent signaled FDB in any size network instead of relying on flooding and learning. Control plane learning also offers greater control over MAC learning, what is signaled, from where and to whom, and maintains virtualization and isolation of EVPN instances. MP-BGP advertises MACs and IPs for next hop resolution with an EVPN NLRI, which fully supports IPv4 and IPv6 in the control and data plane. Yes that\u2019s right, there are no extensions to EVPN for IPv6, it\u2019s completely integrated and supported just like IPv4 from the very beginning. For reference, here are the BGP route types defined for EVPN, and their uses: Route Type Description RFC Use 1 Ethernet auto-discovery route RFC 7432 Advertises list of EVPN Instances (EVIs) per Ethernet segment (ES) 2 MAC/IP advertisement route RFC 7432 Advertises MACs, reachability, and IP/MAC bindings 3 Inclusive multicast route RFC 7432 Advertises per VLAN and per ESI tunnel endpoint discovery for BUM traffic 4 Ethernet segment route RFC 7432 Redundancy group discovery and designated forwarder (DF) election 5 IP prefix route Draft-ietf-bess-evpn-prefix-advertisement-11 Advertises IP prefixes Within EVPN, the separation of the control plane and data plane is key to providing flexibility, control, and efficiency in the network. While we\u2019ll explain the various dataplane encapsulating options supported by EVPN in the next section, the fact that there is an encapsulation dictates that there is both overlay and underlay routing and switching possible. Overlay routing/switching being performed at the edge on ingress of packets into the EVPN services, and underlay routing/switching occurring based on the encapsulated packet in the service-unaware core of the network. The overlays and underlay are making independent routing and switching decisions based on advertisements by their separate control planes. In the underlay section of this document, the use of various control plane options, include eBGP, iBGP, ISIS, and OSPF are explained and compared. For the advertisement of overlay MACs and IPs, EVPN supports the use of either eBGP or iBGP with the Multi-Protocol (MP) BGP extension. The choice between these may be based on the operator\u2019s preference, operations team\u2019s skills set, feature support by the vendor, or based on the configuration requirement differences between them. Both options support very large fabrics, high scale MAC/IP advertisements, tuning options for fast convergence, and similar troubleshooting options. For Nokia, SR Linux supports both models, with the following operational considerations identified for operators to make their choice. eBGP # Configuration of an AS per overlay terminating node, and per spine switch AS reuse possible per overlay terminating node (or pair) eBGP peering between all directly connected nodes in the network Each non overlay terminating node (spine, super-spine), must act as a route server and re-advertise reachability of all overlay terminating nodes without modifying the next-hop This requires support for the eBGP feature - next-hop-unchanged Advantages Overlay path captured in eBGP AS-path attributes No requirement for route reflectors Challenges AS assignment and tracking Additional configuration on spine nodes iBGP # Configuration of a single AS across the overlay terminating nodes iBGP peering: Directly between all overlay terminating nodes (full mesh) Indirectly between overlay terminating nodes via >=1 route reflectors Route reflector must support EVPN family of route types Advantages Simplicity of single AS design Challenges Additional requirement for route reflectors Less path tracking capabilities in the overlay, but can still be done via underlay While there are advantages and challenges for either eBGP or iBGP for the EVPN overlay control plane, the majority of vendors have been advocating iBGP at EANTC interop testing sessions in recent years.","title":"Overview"},{"location":"overview/#evpn-overview","text":"Now that we\u2019ve discussed the motivation and key benefits of EVPN, let\u2019s dive into how the technology is developing. EVPN technology is driven in the IETF L2VPN WG, comprised of a few mature base internet drafts (I-Ds) as well as a plethora of new I-Ds that extend EVPN functionality (over 20 I-Ds in total). No more changes are expected on the base specification, and there are several shipping EVPN implementations. The authors of the EVPN requirements and base specification I-Ds come from a diverse set of router vendors (Nokia (Alcatel-Lucent at the time), Cisco, Juniper) and network operators (Arktan, AT&T, Bloomberg, Verizon). EVPN isn\u2019t just another bright idea that someone came up with in a dark cave by themselves, it\u2019s a collaboration between multiple router vendors and network operators that are working together to define this new technology. FIGURE EVPN introduces the concept of a separate control plane and data plane, which enables IP/MAC learning to be performed in the control plane instead of the data plane. MP-BGP is used as the control plane protocol, which brings proven and inherent BGP control plane scalability to MAC routes, and can even be extended with hierarchy and route reflection. Using control plane learning provides a consistent signaled FDB in any size network instead of relying on flooding and learning. Control plane learning also offers greater control over MAC learning, what is signaled, from where and to whom, and maintains virtualization and isolation of EVPN instances. MP-BGP advertises MACs and IPs for next hop resolution with an EVPN NLRI, which fully supports IPv4 and IPv6 in the control and data plane. Yes that\u2019s right, there are no extensions to EVPN for IPv6, it\u2019s completely integrated and supported just like IPv4 from the very beginning. For reference, here are the BGP route types defined for EVPN, and their uses: Route Type Description RFC Use 1 Ethernet auto-discovery route RFC 7432 Advertises list of EVPN Instances (EVIs) per Ethernet segment (ES) 2 MAC/IP advertisement route RFC 7432 Advertises MACs, reachability, and IP/MAC bindings 3 Inclusive multicast route RFC 7432 Advertises per VLAN and per ESI tunnel endpoint discovery for BUM traffic 4 Ethernet segment route RFC 7432 Redundancy group discovery and designated forwarder (DF) election 5 IP prefix route Draft-ietf-bess-evpn-prefix-advertisement-11 Advertises IP prefixes Within EVPN, the separation of the control plane and data plane is key to providing flexibility, control, and efficiency in the network. While we\u2019ll explain the various dataplane encapsulating options supported by EVPN in the next section, the fact that there is an encapsulation dictates that there is both overlay and underlay routing and switching possible. Overlay routing/switching being performed at the edge on ingress of packets into the EVPN services, and underlay routing/switching occurring based on the encapsulated packet in the service-unaware core of the network. The overlays and underlay are making independent routing and switching decisions based on advertisements by their separate control planes. In the underlay section of this document, the use of various control plane options, include eBGP, iBGP, ISIS, and OSPF are explained and compared. For the advertisement of overlay MACs and IPs, EVPN supports the use of either eBGP or iBGP with the Multi-Protocol (MP) BGP extension. The choice between these may be based on the operator\u2019s preference, operations team\u2019s skills set, feature support by the vendor, or based on the configuration requirement differences between them. Both options support very large fabrics, high scale MAC/IP advertisements, tuning options for fast convergence, and similar troubleshooting options. For Nokia, SR Linux supports both models, with the following operational considerations identified for operators to make their choice.","title":"EVPN Overview"},{"location":"overview/#ebgp","text":"Configuration of an AS per overlay terminating node, and per spine switch AS reuse possible per overlay terminating node (or pair) eBGP peering between all directly connected nodes in the network Each non overlay terminating node (spine, super-spine), must act as a route server and re-advertise reachability of all overlay terminating nodes without modifying the next-hop This requires support for the eBGP feature - next-hop-unchanged Advantages Overlay path captured in eBGP AS-path attributes No requirement for route reflectors Challenges AS assignment and tracking Additional configuration on spine nodes","title":"eBGP"},{"location":"overview/#ibgp","text":"Configuration of a single AS across the overlay terminating nodes iBGP peering: Directly between all overlay terminating nodes (full mesh) Indirectly between overlay terminating nodes via >=1 route reflectors Route reflector must support EVPN family of route types Advantages Simplicity of single AS design Challenges Additional requirement for route reflectors Less path tracking capabilities in the overlay, but can still be done via underlay While there are advantages and challenges for either eBGP or iBGP for the EVPN overlay control plane, the majority of vendors have been advocating iBGP at EANTC interop testing sessions in recent years.","title":"iBGP"},{"location":"topics/","text":"Suggested Topics # Note This was the original brainstorming list of topics within EVPN EVPN services: # Intro \u2013 what problems EVPN is solving Single protocol for all overlay services \u2013 what RFCs, definition of each Route Type 1-5 Table of route types? Transport agnostic Customer separation re-uses BGP control plane \u2013 for advertisement per tenant with MP-BGP Interop (EANTC) Overlay and Underlay EVPN and VXLAN Overlay Control Plane MP-BGP and use of RRs for simplicity Peering considerations and options \u2013 iBGP? EBGP? Jorge question. Complicating with eBGP? New next-hops SR LINUX EVPN # L2 EVPN We offer VXLAN tunneling Diagram of L2 encap and advertisement via BGP Handling of BUM and known unicast traffic All Active, MH, with mobility Loop prevention L3 EVPN EVPN-IRB-unicast We offer VXLAN tunneling Diagram of L3 encap and advertisement via BGP ARP Proxy What we support for inter-subnet forwarding Symmetric and Asymmetric IRB Interface-ful with SBD. Interface-ful with unnumbered SBD IRB. Interface-less. All Active, MH, with mobility Good default versus optimizations for inter/intra-DC etc. Overlay Overview # What and Why do we need them? Layer 2 vs Layer 3 Differences between them in design and where gateways exists etc Life of a packet in each case. BGP EVPN Peering Design iBGP peering, EVPN RRs etc Suggest best practice from Nokia Tuning BGP for EVPN Loop Prevention Overlay and underlay separation # EVPN overlays with MP-BGP Underlay with IGP (OSPF or ISIS) or BGP Distance vector versus link state considerations Resiliency mechanism (detection with BFD?) SRL \u2013 underlay \u2013 OSPF/ISIS or eBGP RFC for hyperscale DC design uses eBGP RFC 7938 - Use of BGP for Routing in Large-Scale Data Centers # Simplicity with ISIS for autodiscovery already possible No need to learn something else AS-path traceability in the underlay \u2013 know the path because each POD has a different AS Not possible with IGP More route policy possibilities with BGP Auto-discovery options with BGP \u2013 lldp w/ extensions LSOE \u2013 LSVR working group is another option Auto-creates BGP ptop sessions Convergence \u2013 IGP is typically faster, but loots of work make BGP fast as well. BFD for BGP for sure, ask bruce about BFD for IGP. Control Plane BGP peering options # eBGP or iBGP typically iBGP \u2013 with router reflectors simple if eBGP \u2013 next hop unchanged allows spines to be route servers common across vendors EANTC \u2013 eBGP in underlay, and iBGP in overlay Arista pushed it which is better for: # eBGP iBGP Big fabric no advantage no advantage Small fabric no advantage no advantage Lots of /32s no advantage no advantage Simplicity of ASN assignments more ASNs single ASN Troubleshooting path attributes slightly less info","title":"Topic List"},{"location":"topics/#suggested-topics","text":"Note This was the original brainstorming list of topics within EVPN","title":"Suggested Topics"},{"location":"topics/#evpn-services","text":"Intro \u2013 what problems EVPN is solving Single protocol for all overlay services \u2013 what RFCs, definition of each Route Type 1-5 Table of route types? Transport agnostic Customer separation re-uses BGP control plane \u2013 for advertisement per tenant with MP-BGP Interop (EANTC) Overlay and Underlay EVPN and VXLAN Overlay Control Plane MP-BGP and use of RRs for simplicity Peering considerations and options \u2013 iBGP? EBGP? Jorge question. Complicating with eBGP? New next-hops","title":"EVPN services:"},{"location":"topics/#sr-linux-evpn","text":"L2 EVPN We offer VXLAN tunneling Diagram of L2 encap and advertisement via BGP Handling of BUM and known unicast traffic All Active, MH, with mobility Loop prevention L3 EVPN EVPN-IRB-unicast We offer VXLAN tunneling Diagram of L3 encap and advertisement via BGP ARP Proxy What we support for inter-subnet forwarding Symmetric and Asymmetric IRB Interface-ful with SBD. Interface-ful with unnumbered SBD IRB. Interface-less. All Active, MH, with mobility Good default versus optimizations for inter/intra-DC etc.","title":"SR LINUX EVPN"},{"location":"topics/#overlay-overview","text":"What and Why do we need them? Layer 2 vs Layer 3 Differences between them in design and where gateways exists etc Life of a packet in each case. BGP EVPN Peering Design iBGP peering, EVPN RRs etc Suggest best practice from Nokia Tuning BGP for EVPN Loop Prevention","title":"Overlay Overview"},{"location":"topics/#overlay-and-underlay-separation","text":"EVPN overlays with MP-BGP Underlay with IGP (OSPF or ISIS) or BGP Distance vector versus link state considerations Resiliency mechanism (detection with BFD?) SRL \u2013 underlay \u2013 OSPF/ISIS or eBGP RFC for hyperscale DC design uses eBGP","title":"Overlay and underlay separation"},{"location":"topics/#rfc-7938-use-of-bgp-for-routing-in-large-scale-data-centers","text":"Simplicity with ISIS for autodiscovery already possible No need to learn something else AS-path traceability in the underlay \u2013 know the path because each POD has a different AS Not possible with IGP More route policy possibilities with BGP Auto-discovery options with BGP \u2013 lldp w/ extensions LSOE \u2013 LSVR working group is another option Auto-creates BGP ptop sessions Convergence \u2013 IGP is typically faster, but loots of work make BGP fast as well. BFD for BGP for sure, ask bruce about BFD for IGP.","title":"RFC 7938 - Use of BGP for Routing in Large-Scale Data Centers"},{"location":"topics/#control-plane-bgp-peering-options","text":"eBGP or iBGP typically iBGP \u2013 with router reflectors simple if eBGP \u2013 next hop unchanged allows spines to be route servers common across vendors EANTC \u2013 eBGP in underlay, and iBGP in overlay Arista pushed it","title":"Control Plane BGP peering options"},{"location":"topics/#which-is-better-for","text":"eBGP iBGP Big fabric no advantage no advantage Small fabric no advantage no advantage Lots of /32s no advantage no advantage Simplicity of ASN assignments more ASNs single ASN Troubleshooting path attributes slightly less info","title":"which is better for:"},{"location":"use-cases/","text":"EVPN Data Center Use Cases # Layer 2 or Layer 3 Inter Data Center Services # Layer 2 or Layer 3 Intra Data Center Services # Layer 2 or Layer 3 Data Center Interconnect # Figure caption: Layer 2 or Layer 3 Data Center Interconnect This DCI application enables scalable Layer 2 or Layer 3 services for virtualized data centers with control plane signaling of IP/MAC mobility for VMs that move between data centers. Local IP gateways at each PE optimize routing, so that external traffic is sent to the closest exit instead of over the internal network to a remote gateway. Integrated Layer 2 switching and Layer 3 routing over the same interface or VLAN enables flexible service delivery to VMs. Data Center to Internet/WAN VPNs/Cloud Interconnect # Figure caption: Layer 2 and Layer 3 Overlay VPNs EVPN is use to provide integrated Layer 2 and Layer 3 VPN services on a single interface and single VLAN to customers. There\u2019s only one VPN technology for both services, and no need for multiple VPN protocols. All-active or single-active PE to CE connections can be supported depending on the requirements for redundancy and load-balancing. The EVPN services can be provided over any core network as described above, MPLS cores can use EVPN-MPLS and IP cores can use EVPN-VXLAN. Figure caption: Flexible Layer 2 and Layer 3 VPN Solution EVPN-VXLAN works over any IP network to provide a flexible Layer 2 and Layer 3 VPN. This application just requires IP connectivity between sites, no MPLS or any special configuration by the IP service provider is needed. There could even be several different IP networks in the path, for example if a network operator bought IP service from different providers at different locations. The service provider network is completely transparent to EVPN, and the EVPN overlay is completely transparent to service providers \u2013 it\u2019s just IP traffic. Routing and MAC/IP advertisement within EVPN are controlled via IBGP or eBGP between PEs.","title":"Use Cases"},{"location":"use-cases/#evpn-data-center-use-cases","text":"","title":"EVPN Data Center Use Cases"},{"location":"use-cases/#layer-2-or-layer-3-inter-data-center-services","text":"","title":"Layer 2 or Layer 3 Inter Data Center Services"},{"location":"use-cases/#layer-2-or-layer-3-intra-data-center-services","text":"","title":"Layer 2 or Layer 3 Intra Data Center Services"},{"location":"use-cases/#layer-2-or-layer-3-data-center-interconnect","text":"Figure caption: Layer 2 or Layer 3 Data Center Interconnect This DCI application enables scalable Layer 2 or Layer 3 services for virtualized data centers with control plane signaling of IP/MAC mobility for VMs that move between data centers. Local IP gateways at each PE optimize routing, so that external traffic is sent to the closest exit instead of over the internal network to a remote gateway. Integrated Layer 2 switching and Layer 3 routing over the same interface or VLAN enables flexible service delivery to VMs.","title":"Layer 2 or Layer 3 Data Center Interconnect"},{"location":"use-cases/#data-center-to-internetwan-vpnscloud-interconnect","text":"Figure caption: Layer 2 and Layer 3 Overlay VPNs EVPN is use to provide integrated Layer 2 and Layer 3 VPN services on a single interface and single VLAN to customers. There\u2019s only one VPN technology for both services, and no need for multiple VPN protocols. All-active or single-active PE to CE connections can be supported depending on the requirements for redundancy and load-balancing. The EVPN services can be provided over any core network as described above, MPLS cores can use EVPN-MPLS and IP cores can use EVPN-VXLAN. Figure caption: Flexible Layer 2 and Layer 3 VPN Solution EVPN-VXLAN works over any IP network to provide a flexible Layer 2 and Layer 3 VPN. This application just requires IP connectivity between sites, no MPLS or any special configuration by the IP service provider is needed. There could even be several different IP networks in the path, for example if a network operator bought IP service from different providers at different locations. The service provider network is completely transparent to EVPN, and the EVPN overlay is completely transparent to service providers \u2013 it\u2019s just IP traffic. Routing and MAC/IP advertisement within EVPN are controlled via IBGP or eBGP between PEs.","title":"Data Center to Internet/WAN VPNs/Cloud Interconnect"},{"location":"l2-evpn/l2-service/","text":"EVPN L2 Service # The basic SR Linux configuration of EVPN-VXLAN for L2 consists of: A bridged sub-interface, which defines the port, VLAN, and policy associated with traffic entering the L2 EVPN service A vxlan-interface, that contains the ingress VNI of the VXLAN tunnel used when transmitting VXLAN packets. A MAC-VRF network-instance where, in addition to other sub-interfaces, the vxlan-interface is attached. BGP-EVPN is also enabled in the same MAC-VRF with a minimum configuration of the EVI and the network-instance vxlan-interface associated to it. EVPN L2 Basic Routes # The basic EVPN Layer-2 model requires the implementation of the BGP-EVPN address family and the support for two route types that are illustrated in the following Figure. EVPN MAC/IP route (or type 2, RT2) EVPN Inclusive Multicast Ethernet Tag route (IMET or type 3, RT3) Figure \u2013 EVPN-VXLAN Basic L2 routes The MAC/IP route is used to convey the MAC and IP information of hosts connected to sub-interfaces in the MAC-VRF. The IMET route is advertised as soon as bgp-evpn is enabled in the MAC-VRF and it has a twofold purpose: The auto-discovery of the remote VTEPs attached to the same EVI. The creation of a default flooding list in the MAC-VRF so that BUM frames are replicated. As in SROS, the MAC Mobility extended community is required along with the RT2s for mobility procedures (Sequence Number) and for the Static bit that will be used to advertised static MACs and learned-static MACs. Both RT2 and RT3 are advertised along with the bgp encapsulation extended community. The advertisement of the MAC/IP and IMET routes can be controlled on a per MAC-VRF basis. EVPN L2 Packet Walkthrough # The following figures illustrate a basic packet walkthrough for the communication between two hosts of the same broadcast domain, including the initial ARP resolution. LEAF-\u00bd/3 use the information conveyed in the IMET routes from the remote NVEs to create a flooding list that consists of the [VTEP:VNI] pairs of the two remote Leafs. In addition, the leafs populate their Bridge Table with the MAC addresses contained in the received MAC/IP routes. Figure \u2013 EVPN-VXLAN L2 model \u2013 Packet walkthrough The steps depicted in Figure \"EVPN-VXLAN L2 model \u2013 BUM packet walkthrough\" can be summarized as: # Initial Control Plane exchange: as soon as the network-instances for the same route-target are enabled on the three leafs, Inclusive Multicast Ethernet Tag (IMET) routes are exchanged. Leaf nodes create their flood list for the mac-vrf upon processing the received IMET routes. Frames are identified for a mac lookup in the bridge-table based on the ingress sub-interface. The sub-interface will also provide the ingress vlan manipulation action. The mac lookup is twofold: A mac destination address lookup yields no entry (since the MAC DA is broadcast), hence the frame is identified to forward to the flooding list. A mac source address lookup yields no entry, hence the frame is sent to CPM for mac learning. The frame is flooded, and the MAC SA advertised in EVPN. The frame to be flooded is encapsulated in a VXLAN packet with the source-vtep address and VNI for the service. Two copies (each one with a different tunnel IP DA) are sent to the default network-instance to be routed to the remote vteps LEAF-2 and LEAF-3. ECMP and LAG spraying are applied to each packet. Also, if the outbound sub-interface is tagged, a vlan tag will be pushed into the egress packet. In parallel, the MAC SA is learned by the l2maclearn_mgr, selected/installed by the l2mac_mgr and advertised by evpn_mgr in a MAC/IP route. At the egress Leafs, the flooded VXLAN packet is identified for mac-vrf 1 processing, based on the outer VID and VXLAN VNI. At the same time, the MAC/IP routes containing M1 are received, imported and installed in LEAF-\u2154 bridge tables. The inner MAC DA is identified for mac lookup in the bridge table. Since the MAC DA lookup fails to find an entry, the decapsulated frame will be flooded based on the local flood list and observing the split-horizon rules (that avoid forwarding back to vxlan), thus providing loop prevention. Vlan manipulation is applied based on the egress sub-interfaces configuration. Figure \u2013 EVPN-VXLAN L2 model \u2013 Unicast packet walkthrough The ARP Request eventually gets to the CE with MAC M2. It replies with a unicast ARP reply destined to M1. The frame is classified for mac lookup as in steps 2 and 3. This time the mac destination lookup yields an entry in the bridge table. The source mac lookup follows step 3. The process of learning, advertising and installing M2 is the same as for M1. The unicast VXLAN packet is forwarded to LEAF-1 using its VTEP. The packet is classified for mac-vrf processing based on the outer VID and VNI. Now the mac destination lookup yields an entry pointing at sub-interface eth-1/1-1. The inner frame is forwarded to the sub-interface, after going through the egress vlan manipulation process. Loop prevention: # As is highlighted above, when an unknown MAC-DA is received from a host, the packet is flooded to the local flood list, as well as to the remote devices learnt via the IMET routes sharing the same VNI. When unknown MAC-DAs are received from a VXLAN tunnel (ie flooded from a remote endpoint), again the packet is flooded to the local flood list. In these cases though, as well as when dual-homing of CEs occurs with the associated EVPN Segment Identifier (ESI) definition, split-horizon rules within SR LINUX ensure that the flooded packet is NOT flooded back from where it was received, this being either a host, ESI, or VXLAN tunnel. The result of this is effective loop prevention in an EVPN L2 service.","title":"L2 Service"},{"location":"l2-evpn/l2-service/#evpn-l2-service","text":"The basic SR Linux configuration of EVPN-VXLAN for L2 consists of: A bridged sub-interface, which defines the port, VLAN, and policy associated with traffic entering the L2 EVPN service A vxlan-interface, that contains the ingress VNI of the VXLAN tunnel used when transmitting VXLAN packets. A MAC-VRF network-instance where, in addition to other sub-interfaces, the vxlan-interface is attached. BGP-EVPN is also enabled in the same MAC-VRF with a minimum configuration of the EVI and the network-instance vxlan-interface associated to it.","title":"EVPN L2 Service"},{"location":"l2-evpn/l2-service/#evpn-l2-basic-routes","text":"The basic EVPN Layer-2 model requires the implementation of the BGP-EVPN address family and the support for two route types that are illustrated in the following Figure. EVPN MAC/IP route (or type 2, RT2) EVPN Inclusive Multicast Ethernet Tag route (IMET or type 3, RT3) Figure \u2013 EVPN-VXLAN Basic L2 routes The MAC/IP route is used to convey the MAC and IP information of hosts connected to sub-interfaces in the MAC-VRF. The IMET route is advertised as soon as bgp-evpn is enabled in the MAC-VRF and it has a twofold purpose: The auto-discovery of the remote VTEPs attached to the same EVI. The creation of a default flooding list in the MAC-VRF so that BUM frames are replicated. As in SROS, the MAC Mobility extended community is required along with the RT2s for mobility procedures (Sequence Number) and for the Static bit that will be used to advertised static MACs and learned-static MACs. Both RT2 and RT3 are advertised along with the bgp encapsulation extended community. The advertisement of the MAC/IP and IMET routes can be controlled on a per MAC-VRF basis.","title":"EVPN L2 Basic Routes"},{"location":"l2-evpn/l2-service/#evpn-l2-packet-walkthrough","text":"The following figures illustrate a basic packet walkthrough for the communication between two hosts of the same broadcast domain, including the initial ARP resolution. LEAF-\u00bd/3 use the information conveyed in the IMET routes from the remote NVEs to create a flooding list that consists of the [VTEP:VNI] pairs of the two remote Leafs. In addition, the leafs populate their Bridge Table with the MAC addresses contained in the received MAC/IP routes. Figure \u2013 EVPN-VXLAN L2 model \u2013 Packet walkthrough","title":"EVPN L2 Packet Walkthrough"},{"location":"l2-evpn/l2-service/#the-steps-depicted-in-figure-evpn-vxlan-l2-model-bum-packet-walkthrough-can-be-summarized-as","text":"Initial Control Plane exchange: as soon as the network-instances for the same route-target are enabled on the three leafs, Inclusive Multicast Ethernet Tag (IMET) routes are exchanged. Leaf nodes create their flood list for the mac-vrf upon processing the received IMET routes. Frames are identified for a mac lookup in the bridge-table based on the ingress sub-interface. The sub-interface will also provide the ingress vlan manipulation action. The mac lookup is twofold: A mac destination address lookup yields no entry (since the MAC DA is broadcast), hence the frame is identified to forward to the flooding list. A mac source address lookup yields no entry, hence the frame is sent to CPM for mac learning. The frame is flooded, and the MAC SA advertised in EVPN. The frame to be flooded is encapsulated in a VXLAN packet with the source-vtep address and VNI for the service. Two copies (each one with a different tunnel IP DA) are sent to the default network-instance to be routed to the remote vteps LEAF-2 and LEAF-3. ECMP and LAG spraying are applied to each packet. Also, if the outbound sub-interface is tagged, a vlan tag will be pushed into the egress packet. In parallel, the MAC SA is learned by the l2maclearn_mgr, selected/installed by the l2mac_mgr and advertised by evpn_mgr in a MAC/IP route. At the egress Leafs, the flooded VXLAN packet is identified for mac-vrf 1 processing, based on the outer VID and VXLAN VNI. At the same time, the MAC/IP routes containing M1 are received, imported and installed in LEAF-\u2154 bridge tables. The inner MAC DA is identified for mac lookup in the bridge table. Since the MAC DA lookup fails to find an entry, the decapsulated frame will be flooded based on the local flood list and observing the split-horizon rules (that avoid forwarding back to vxlan), thus providing loop prevention. Vlan manipulation is applied based on the egress sub-interfaces configuration. Figure \u2013 EVPN-VXLAN L2 model \u2013 Unicast packet walkthrough The ARP Request eventually gets to the CE with MAC M2. It replies with a unicast ARP reply destined to M1. The frame is classified for mac lookup as in steps 2 and 3. This time the mac destination lookup yields an entry in the bridge table. The source mac lookup follows step 3. The process of learning, advertising and installing M2 is the same as for M1. The unicast VXLAN packet is forwarded to LEAF-1 using its VTEP. The packet is classified for mac-vrf processing based on the outer VID and VNI. Now the mac destination lookup yields an entry pointing at sub-interface eth-1/1-1. The inner frame is forwarded to the sub-interface, after going through the egress vlan manipulation process.","title":"The steps depicted in Figure \"EVPN-VXLAN L2 model \u2013 BUM packet walkthrough\" can be summarized as:"},{"location":"l2-evpn/l2-service/#loop-prevention","text":"As is highlighted above, when an unknown MAC-DA is received from a host, the packet is flooded to the local flood list, as well as to the remote devices learnt via the IMET routes sharing the same VNI. When unknown MAC-DAs are received from a VXLAN tunnel (ie flooded from a remote endpoint), again the packet is flooded to the local flood list. In these cases though, as well as when dual-homing of CEs occurs with the associated EVPN Segment Identifier (ESI) definition, split-horizon rules within SR LINUX ensure that the flooded packet is NOT flooded back from where it was received, this being either a host, ESI, or VXLAN tunnel. The result of this is effective loop prevention in an EVPN L2 service.","title":"Loop prevention:"},{"location":"l3-evpn/asymmetric/","text":"EVPN L3 - Asymmetric IRB Model # The asymmetric model is considered to be the basic L3 forwarding model when the ip-vrf interfaces are all IRB based. The asymmetric model assumes that all the subnets of a tenant are local in the ip-vrf route-table, hence there is no need to advertise EVPN RT5s. Figure \u2013 EVPN-VXLAN L3 model \u2013 Asymmetric forwarding illustrates this model. Figure \u2013 EVPN-VXLAN L3 model \u2013 Asymmetric forwarding In Figure \u2013 EVPN-VXLAN L3 model \u2013 Asymmetric forwarding: The host with IP address 10.1 sends a unicast packet with destination 20.1 (host in a different subnet and remote leaf). Since the IP DA is in a remote subnet, the MAC DA will be resolved to the local default gateway, mac M-IRB1. The frame is classified for mac lookup on mac-vrf 1, and the result is IRB.1, which indicates that an IP DA lookup is required in ip-vrf red. An IP DA longest prefix match in the route-table yields IRB.2, a local IRB interface, hence an ARP and MAC DA lookups are required in the corresponding IRB interface and mac-vrf bridge table. The ARP lookup yields M2 on mac-vrf 2, and M2 lookup yields vxlan destination [VTEP:VNI]=[2.2.2.2:2]. The routed packet is encapsulated with the corresponding inner MAC header and VXLAN encapsulation before being sent to the wire. At the egress leaf, the frame is classified for a mac lookup on mac-vrf 2, which yields a local sub- interface where the frame is sent to. Note The \u201casymmetric\u201d name refers to the fact that there are more lookups performed at the ingress leaf than at the egress leaf (as opposed to \u201csymmetric\u201d which implies the same number of lookups at ingress and egress). While this asymmetric model allows inter-subnet-forwarding in EVPN-VXLAN networks in a very simple way, it has some scale implications: It requires the instantiation of all the mac-vrfs of all the tenant subnets on all the leafs attached to the tenant. This is a considerable configuration burden that is only needed when all the leafs have hosts in all the subnets of the tenant. Since all the mac-vrfs of the tenant are instantiated, FDB and ARP entries are consumed for all the hosts in all the leafs of the tenant. E.g., in Figure \u2013 EVPN-VXLAN L3 model \u2013 Asymmetric forwarding, leaf-1 needs to install the ARP and FDB entries for host with IP address 20.1, even if the host is not attached to leaf-1. Likewise, for host 10.1 in leaf-2. Those scale implications make a symmetric model needed in any DC deployment.","title":"Asymmetric Routing"},{"location":"l3-evpn/asymmetric/#evpn-l3-asymmetric-irb-model","text":"The asymmetric model is considered to be the basic L3 forwarding model when the ip-vrf interfaces are all IRB based. The asymmetric model assumes that all the subnets of a tenant are local in the ip-vrf route-table, hence there is no need to advertise EVPN RT5s. Figure \u2013 EVPN-VXLAN L3 model \u2013 Asymmetric forwarding illustrates this model. Figure \u2013 EVPN-VXLAN L3 model \u2013 Asymmetric forwarding In Figure \u2013 EVPN-VXLAN L3 model \u2013 Asymmetric forwarding: The host with IP address 10.1 sends a unicast packet with destination 20.1 (host in a different subnet and remote leaf). Since the IP DA is in a remote subnet, the MAC DA will be resolved to the local default gateway, mac M-IRB1. The frame is classified for mac lookup on mac-vrf 1, and the result is IRB.1, which indicates that an IP DA lookup is required in ip-vrf red. An IP DA longest prefix match in the route-table yields IRB.2, a local IRB interface, hence an ARP and MAC DA lookups are required in the corresponding IRB interface and mac-vrf bridge table. The ARP lookup yields M2 on mac-vrf 2, and M2 lookup yields vxlan destination [VTEP:VNI]=[2.2.2.2:2]. The routed packet is encapsulated with the corresponding inner MAC header and VXLAN encapsulation before being sent to the wire. At the egress leaf, the frame is classified for a mac lookup on mac-vrf 2, which yields a local sub- interface where the frame is sent to. Note The \u201casymmetric\u201d name refers to the fact that there are more lookups performed at the ingress leaf than at the egress leaf (as opposed to \u201csymmetric\u201d which implies the same number of lookups at ingress and egress). While this asymmetric model allows inter-subnet-forwarding in EVPN-VXLAN networks in a very simple way, it has some scale implications: It requires the instantiation of all the mac-vrfs of all the tenant subnets on all the leafs attached to the tenant. This is a considerable configuration burden that is only needed when all the leafs have hosts in all the subnets of the tenant. Since all the mac-vrfs of the tenant are instantiated, FDB and ARP entries are consumed for all the hosts in all the leafs of the tenant. E.g., in Figure \u2013 EVPN-VXLAN L3 model \u2013 Asymmetric forwarding, leaf-1 needs to install the ARP and FDB entries for host with IP address 20.1, even if the host is not attached to leaf-1. Likewise, for host 10.1 in leaf-2. Those scale implications make a symmetric model needed in any DC deployment.","title":"EVPN L3 - Asymmetric IRB Model"},{"location":"l3-evpn/l3-service/","text":"EVPN L3 Services # MAC-VRF, IRB, IP-VRF The basic EVPN Layer-3 model builds upon the model of the EVPN routes described in section EVPN-VXLAN L2 and extends it with a new route type to support inter-subnet-forwarding: EVPN IP Prefix route (or type 5, RT5) # The IP Prefix route is used to convey IP Prefixes of any length and family that need to be installed in the ip- vrfs of remote leaf nodes. The EVPN Layer-3 model is also known in the standards as the EVPN IRB Model (because it uses IRB interfaces in ip-vrfs connected to mac-vrfs), and it has two required modes of operation: Asymmetric IRB - see [IETF-EVPN-IRB] Symmetric IRB, which can be classified as: Host routing model using RT2s - see [IETF-EVPN-IRB] Prefix routing model using RT5s - see [IETF-EVPN-L3]. This one can be classified as: Interface-less ip-vrf-to-ip-vrf model (IFL) Interface-ful ip-vrf-to-ip-vrf model (IFF) The asymmetric IRB mode is required in SRLinux, since it is considered a basic mode of operation for IRB interfaces. As for the symmetric IRB model, the \u201cHost routing model using RT2s\u201d uses RT2s with an L2 and an L3 VNI, so that the IP address conveyed in the route is installed in the ip-vrf route-table as a host route, associated to the L3 VNI. This model is NOT REQUIRED in SRLinux. The Prefix routing model is REQUIRED in SRLinux. The following table summarizes the models and requirements. EVPN L3 Models: Model Value Industry Support SR Linux Support Asymmetric Basic IRB forwarding All vendors Yes Symmetric Host Routing with RT2s The same RT2 is used to populate FDB, ARP, and route-table (as opposed to RT2 for FDB/ARP, and RT5 for route-table) Cisco only No Prefix Routing with RT5s Interface Less (IFL) Uses RT5 in a similar way to IPVPN routes All vendors Yes Interface-Full (IFF) - numbered Uses RT5 with recursive resolution to RT2 SROS, Juniper MX Yes Interface-Full (IFF) - unnumbered Same as above but does not use IP addresses in the core IRB interfaces SROS, Nuage, Cisco Nexus Yes The standard SR Linux configuration components of L3 services are illustrated below. FIGURE - EVPN-VXLAN L3 INTER-SUBNET FORWARDING IN OVERLAY DCS To understand the EVPN L3 model which will be most suitable to a deployment, each option must be explained.","title":"L3 Service"},{"location":"l3-evpn/l3-service/#evpn-l3-services","text":"MAC-VRF, IRB, IP-VRF The basic EVPN Layer-3 model builds upon the model of the EVPN routes described in section EVPN-VXLAN L2 and extends it with a new route type to support inter-subnet-forwarding:","title":"EVPN L3 Services"},{"location":"l3-evpn/l3-service/#evpn-ip-prefix-route-or-type-5-rt5","text":"The IP Prefix route is used to convey IP Prefixes of any length and family that need to be installed in the ip- vrfs of remote leaf nodes. The EVPN Layer-3 model is also known in the standards as the EVPN IRB Model (because it uses IRB interfaces in ip-vrfs connected to mac-vrfs), and it has two required modes of operation: Asymmetric IRB - see [IETF-EVPN-IRB] Symmetric IRB, which can be classified as: Host routing model using RT2s - see [IETF-EVPN-IRB] Prefix routing model using RT5s - see [IETF-EVPN-L3]. This one can be classified as: Interface-less ip-vrf-to-ip-vrf model (IFL) Interface-ful ip-vrf-to-ip-vrf model (IFF) The asymmetric IRB mode is required in SRLinux, since it is considered a basic mode of operation for IRB interfaces. As for the symmetric IRB model, the \u201cHost routing model using RT2s\u201d uses RT2s with an L2 and an L3 VNI, so that the IP address conveyed in the route is installed in the ip-vrf route-table as a host route, associated to the L3 VNI. This model is NOT REQUIRED in SRLinux. The Prefix routing model is REQUIRED in SRLinux. The following table summarizes the models and requirements. EVPN L3 Models: Model Value Industry Support SR Linux Support Asymmetric Basic IRB forwarding All vendors Yes Symmetric Host Routing with RT2s The same RT2 is used to populate FDB, ARP, and route-table (as opposed to RT2 for FDB/ARP, and RT5 for route-table) Cisco only No Prefix Routing with RT5s Interface Less (IFL) Uses RT5 in a similar way to IPVPN routes All vendors Yes Interface-Full (IFF) - numbered Uses RT5 with recursive resolution to RT2 SROS, Juniper MX Yes Interface-Full (IFF) - unnumbered Same as above but does not use IP addresses in the core IRB interfaces SROS, Nuage, Cisco Nexus Yes The standard SR Linux configuration components of L3 services are illustrated below. FIGURE - EVPN-VXLAN L3 INTER-SUBNET FORWARDING IN OVERLAY DCS To understand the EVPN L3 model which will be most suitable to a deployment, each option must be explained.","title":"EVPN IP Prefix route (or type 5, RT5)"},{"location":"l3-evpn/symmetric/","text":"EVPN L3 - Symmetric IRB - Prefix Routing Model # Figure \u2013 EVPN-VXLAN L3 model \u2013 Symmetric forwarding illustrates the forwarding in a symmetric model. In Figure \u2013 EVPN-VXLAN L3 model \u2013 Symmetric forwarding: As in the asymmetric model, the frame is classified for bridge table lookup on mac-vrf and processed for routing in ip-vrf red. Contrary to the asymmetric model, a longest prefix match does not yield a local subnet, but a remote subnet reachable via [VTEP:VNI]=[2.2.2.2:3] and inner MAC DA R-MAC2. Depending on the sub-model implemented, Interface-less (IFL) or Interface-ful (IFF), that information is found in the ip- vrf route-table directly (IFL) or via recursive lookup into the ip-vrf route-table and a core SBD mac- vrf. NOTE: refer to Annex to see the details and differences between the IFL and IFF sub-models. At the egress PE, the packet is classified for an ip lookup on the ip-vrf red. Again, the way the ip-vrf red is found, depends on whether the implemented sub-model is IFL or IFF. The ip lookup yields a local IRB interface. Subsequent ARP and MAC lookups provide the information to send the routed frame onto the wire to sub-interface 2. Note The \u201csymmetric\u201d name refers to the fact that a mac and ip lookups are needed at ingress, while ip and mac lookups are performed at egress. Compared to the asymmetric model, this model scales much better since hosts\u2019 ARP and FDB entries will be installed only on the directly attached leafs and not on all the leafs of the tenant. CE connectivity options \u2013 single and dual homed: # EVPN covers a variety of connectivity options for CE devices into EVPN L2 and L3 services. These include single and dual homing with various support forwarding behaviours and parameters, including Active/Standby and All Active. These will be covered in their own section of this document.","title":"Symmetric Routing"},{"location":"l3-evpn/symmetric/#evpn-l3-symmetric-irb-prefix-routing-model","text":"Figure \u2013 EVPN-VXLAN L3 model \u2013 Symmetric forwarding illustrates the forwarding in a symmetric model. In Figure \u2013 EVPN-VXLAN L3 model \u2013 Symmetric forwarding: As in the asymmetric model, the frame is classified for bridge table lookup on mac-vrf and processed for routing in ip-vrf red. Contrary to the asymmetric model, a longest prefix match does not yield a local subnet, but a remote subnet reachable via [VTEP:VNI]=[2.2.2.2:3] and inner MAC DA R-MAC2. Depending on the sub-model implemented, Interface-less (IFL) or Interface-ful (IFF), that information is found in the ip- vrf route-table directly (IFL) or via recursive lookup into the ip-vrf route-table and a core SBD mac- vrf. NOTE: refer to Annex to see the details and differences between the IFL and IFF sub-models. At the egress PE, the packet is classified for an ip lookup on the ip-vrf red. Again, the way the ip-vrf red is found, depends on whether the implemented sub-model is IFL or IFF. The ip lookup yields a local IRB interface. Subsequent ARP and MAC lookups provide the information to send the routed frame onto the wire to sub-interface 2. Note The \u201csymmetric\u201d name refers to the fact that a mac and ip lookups are needed at ingress, while ip and mac lookups are performed at egress. Compared to the asymmetric model, this model scales much better since hosts\u2019 ARP and FDB entries will be installed only on the directly attached leafs and not on all the leafs of the tenant.","title":"EVPN L3 - Symmetric IRB - Prefix Routing Model"},{"location":"l3-evpn/symmetric/#ce-connectivity-options-single-and-dual-homed","text":"EVPN covers a variety of connectivity options for CE devices into EVPN L2 and L3 services. These include single and dual homing with various support forwarding behaviours and parameters, including Active/Standby and All Active. These will be covered in their own section of this document.","title":"CE connectivity options \u2013 single and dual homed:"}]}